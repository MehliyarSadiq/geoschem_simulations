{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./tools.ipynb\n",
    "%run bio_flux_functions_TransCom.ipynb\n",
    "print('-'*50)\n",
    "print('loaded all the packages and functions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inversion configurations\n",
    "year        = 2016\n",
    "assim_month = 3      # first month to assimilate observation, start from 3, Mar\n",
    "lag_window  = 3      # months\n",
    "nx          = 67     # number of tagged tracers, same as number of masks\n",
    "mode        = 'N'    # OCO-2 Nadir only\n",
    "mod_err     = 1.5    #1.5 # model/transport error, unit: ppm\n",
    "land_prior_err  = 0.5 #0.5 # intial prior error, unitless, multiply biospheric flux for actual prior error\n",
    "ocean_prior_err = 0.3\n",
    "snow_prior_err  = 0.1\n",
    "\n",
    "tag_case_name = 'CO2-TC67-' + str(year) + '-'\n",
    "\n",
    "# full CO2 simulation directory\n",
    "top_dir = '/scratch/local/msadiq/rundir/' + str(year) + '/'\n",
    "#top_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/' + str(year) + '/'\n",
    "\n",
    "name_month = short_name_of_month(assim_month) # Jan, Feb, Mar, ...\n",
    "# read in data from current directory, analyze\n",
    "curr_dir = top_dir + 'CO2-' + str(year) + '/nd51/' + name_month + '/'\n",
    "# output in next directory\n",
    "next_dir = top_dir + 'CO2-' + str(year) + '/nd51/' + short_name_of_month(assim_month+1) + '/'\n",
    "\n",
    "print('-'*50)\n",
    "print('started inversion calculation for ' + str(year) + ' ' + short_name_of_month(assim_month))\n",
    "print('current working directory:')\n",
    "print(curr_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### this cell could do all post-processing for a case, over a few months, or a month\n",
    "\n",
    "print('-'*50)\n",
    "print('post-processing outputs from previous run')\n",
    "\n",
    "for imonth in range(assim_month-lag_window+1,assim_month+1):\n",
    "\n",
    "    bpch_to_nc_mass(data_dir = curr_dir,\n",
    "                        year = year,\n",
    "                        month = imonth)\n",
    "\n",
    "    combine_daily_to_one(data_dir = curr_dir,\n",
    "                         year = year,\n",
    "                         month = imonth,\n",
    "                         str1 = 'ts_satellite.',\n",
    "                         str2 = '.nc')\n",
    "\n",
    "    flatten_4d_to_2d(data_dir = curr_dir,\n",
    "                         year = year,\n",
    "                         month = imonth,\n",
    "                         str1 = 'ts_satellite.',\n",
    "                         str2 = '.nc')\n",
    "    \n",
    "    interpolate_model_to_satellite(mod_dir = curr_dir, \n",
    "                                       sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "                                       year = year, \n",
    "                                       month = imonth, \n",
    "                                       str1_mod = '2d_ts_satellite.', \n",
    "                                       str1_sat = '2d_OCO2_extract_')\n",
    "    compare_XCO2(mod_dir = curr_dir, \n",
    "                 sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "                 year = year, \n",
    "                 month = imonth, \n",
    "                 str1_mod = 'interpolated_2d_ts_satellite.', \n",
    "                 str1_sat = '2d_OCO2_extract_',\n",
    "                 mode = 'N')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('calculating sinks used in previous run')\n",
    "\n",
    "input_dir = '/geos/u73/msadiq/GEOS-Chem/HEMCO/CO2/v2020-04/'\n",
    "\n",
    "if year == 2016 and assim_month == 3:\n",
    "    f1 = input_dir + 'NEE.Liang.2016.nc'\n",
    "    f2 = input_dir + 'Taka2009_CO2_Monthly.nc'\n",
    "else:\n",
    "    f1 = input_dir + 'NEE.Liang.2016.updated.' + str(year) + '.' + short_name_of_month(assim_month-1) + '.nc'\n",
    "    f2 = input_dir + 'Taka2009_CO2_Monthly.updated.' + str(year) + '.' + short_name_of_month(assim_month-1) + '.nc'\n",
    "    \n",
    "monthly_bio_flux = regional_monthly_sink(f1, f2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('prior error matrix')\n",
    "\n",
    "# initial prior error\n",
    "del_X_f = np.diag(np.repeat(land_prior_err,nx))\n",
    "for i in range(55, nx-1): \n",
    "    del_X_f[i,i] = ocean_prior_err # ocean and low emission regions\n",
    "del_X_f[nx-1,nx-1] = snow_prior_err # snow region\n",
    "\n",
    "# prior error, read in from previous assimilation (if any)\n",
    "if year == 2016 and assim_month == 3:\n",
    "    del_X_lag = np.zeros((nx*lag_window,nx*lag_window))\n",
    "    for i in range(lag_window): \n",
    "        del_X_lag[i*nx:(i+1)*nx,i*nx:(i+1)*nx] = del_X_f #[nx*nlag, nx*nlag], diag,\n",
    "else:        \n",
    "    del_X_lag = np.loadtxt(curr_dir + \"prior_error_\" + short_name_of_month(assim_month) + \".txt\")\n",
    "    \n",
    "print('diagonal:', np.diag(del_X_lag))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('inversion calculation')\n",
    "\n",
    "# start of inversion calculation:\n",
    "# 1, read in from full CO2 simulations\n",
    "\n",
    "xco2_file = 'XCO2_mod_and_oco2_N_' + name_month + '.nc'\n",
    "ds_xco2 = xr.open_dataset(curr_dir + xco2_file)\n",
    "xco2_oco2  = ds_xco2['xco2_oco2']  # XCO2 from OCO-2\n",
    "xco2_model = ds_xco2['xco2_model'] # XCO2 from model\n",
    "xco2_error = ds_xco2['xco2_error'] # measurement error from OCO-2\n",
    "diff = ds_xco2['xco2_oco2'] - ds_xco2['xco2_model']\n",
    "\n",
    "# reduce the size of above arrays and matrices, from ~400k to <3k\n",
    "x = xco2_oco2.copy()\n",
    "x = x[np.logical_not(np.isnan(x))]\n",
    "ind = x.record.values   # index for slicing\n",
    "nobs = len(ind) # number of obs in this month\n",
    "# get slices of arrays\n",
    "diff_slice = diff[ind].values            # [nobs], 1-3k per month\n",
    "lat_slice = ds_xco2.lat[ind]\n",
    "lon_slice = ds_xco2.lon[ind]\n",
    "xco2_mod_slice = xco2_model[ind]\n",
    "xco2_oco_slice = xco2_oco2[ind]\n",
    "xco2_error_slice = xco2_error[ind].values \n",
    "\n",
    "# observation error\n",
    "obs_error = np.zeros((nobs,nobs))  # [nobs,nobs], diagonally store obs error\n",
    "for idiag in range(nobs):\n",
    "    obs_error[idiag, idiag] = (0.5*xco2_error_slice[idiag])**2 + mod_err**2\n",
    "    # measurment error from oco2\n",
    "    # model error and representation error = 2.5 for land\n",
    "        \n",
    "# delta y0\n",
    "del_Y = np.empty((nobs,nx*lag_window))   # [nobs, nx*lag_window]\n",
    "del_Y[:] = np.nan\n",
    "\n",
    "# 2, read in tag runs\n",
    "for itmp in range(lag_window):\n",
    "    ilag_month = assim_month - lag_window + itmp + 1\n",
    "    ens_dir = top_dir + tag_case_name + month_string(ilag_month) + '/nd51/'\n",
    "    delta_y0_file = 'delta_y0_model_N_' + str(assim_month) + '.nc'\n",
    "    # open datasets\n",
    "    ds_delta_y0 = xr.open_dataset(ens_dir + delta_y0_file)\n",
    "    varnames = list(ds_delta_y0.data_vars.keys())  # list of variable name\n",
    "    needed_vars = [i for i in varnames if i.startswith('X_SpeciesConc_CO2Tag')] # species var names\n",
    "    # read variables\n",
    "    for itag, ivar in enumerate(needed_vars):\n",
    "        del_Y[:,itag+nx*itmp] = ds_delta_y0[ivar][ind].values # column order: assim_month - 2, assim_month - 1, assim_month\n",
    "\n",
    "del_Y0 = del_Y\n",
    "del_Y = np.dot(del_Y, del_X_lag)   \n",
    "# calculation of posterior\n",
    "del_Y_tran = np.matrix.transpose(del_Y)     # del_y transpose [nx*lag_window,nobs]\n",
    "first      = np.matmul(del_Y,del_Y_tran)    # del_y dot del_y_tran [nobs,nobs]\n",
    "second     = np.linalg.inv(first+obs_error) # (Y*Yt + R)^-1 [nobs,nobs], dominated by second term, issue???\n",
    "third      = np.matmul(del_Y_tran,second)   # Yt*(Y*Yt + R)^-1 [nx*lag_window,nobs]\n",
    "k_e        = np.matmul(del_X_lag,third)     # kalman gain, k_e = X_f*Yt*(Y*Yt + R)^-1 [nx*lag_window,nobs]\n",
    "adjust     = np.matmul(k_e, diff_slice)     # adjustment to prior, k_e*(yobs - ym)  [nx*lag_window]\n",
    "\n",
    "update = adjust * monthly_bio_flux[assim_month-lag_window:assim_month].flatten()\n",
    "# monthly updates\n",
    "for i in range(lag_window):\n",
    "    print(short_name_of_month(assim_month - lag_window + i + 1), 'adjustment: {:.2f}'.format(sum(update[i*nx:(i+1)*nx])))\n",
    "\n",
    "# update Y matrix\n",
    "diff_new = diff_slice - np.dot(del_Y0,adjust) # [nobs], ppm\n",
    "plot_xco2_diff(diff_slice, diff_new, lat_slice, lon_slice, assim_month, curr_dir)\n",
    "\n",
    "# transformation matrix to update prior\n",
    "fourth = np.identity(nx*lag_window) - np.matmul(third, del_Y)\n",
    "transform_mat = sp.sqrtm(fourth)\n",
    "del_X_lag = np.matmul(del_X_lag, transform_mat)\n",
    "\n",
    "# update del_X_lag and use it in next assimilation\n",
    "del_X_updated = np.zeros((nx*lag_window,nx*lag_window))\n",
    "del_X_updated[:(lag_window-1)*nx, :(lag_window-1)*nx] = del_X_lag[nx:,nx:]\n",
    "del_X_updated[(lag_window-1)*nx:, (lag_window-1)*nx:] = del_X_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function\n",
    "# J = (x-x_b)_transpose * B * (x-x_b) + (y-h(x))_transpose * R * (y-h(x))\n",
    "first_half = 0.\n",
    "second_half = np.dot(np.dot(np.matrix.transpose(diff_slice),np.linalg.inv(obs_error)), diff_slice)\n",
    "J = first_half + second_half\n",
    "print('before inversion cost of x:', first_half)\n",
    "print('before inversion cost of y:', second_half)\n",
    "\n",
    "x_diff = update # x - prior\n",
    "B = del_X_lag # prior error covariance matrix \n",
    "first_half = np.dot(np.dot(np.matrix.transpose(x_diff),np.linalg.inv(B)), x_diff)\n",
    "second_half = np.dot(np.dot(np.matrix.transpose(diff_new),np.linalg.inv(obs_error)), diff_new)\n",
    "J = first_half + second_half\n",
    "print('after inversion cost of x:', first_half)\n",
    "print('after inversion cost of y:', second_half)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to update biospheric flux in total CO2 simulations\n",
    "scale_array = 1+adjust\n",
    "scale_lag = scale_array.reshape(lag_window,nx) # 2d\n",
    "\n",
    "#scale_lag = np.flip(scale_lag, axis = 0) # flip?\n",
    "\n",
    "for i in range(lag_window): \n",
    "    #plt.plot(scale_lag[i], label = short_name_of_month(assim_month - lag_window + i + 1))\n",
    "    print(short_name_of_month(assim_month - lag_window + i + 1), ' scaling factors:')\n",
    "    print(scale_lag[i])\n",
    "#plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-'*50)\n",
    "print('update fluxes')\n",
    "\n",
    "# monthly fluxes of sinks\n",
    "dr_sink = monthly_sink(f1, f2) # (12,144,91)\n",
    "\n",
    "# use TransCom masks\n",
    "fname = '/geos/u73/msadiq/GEOS-Chem/MASKS/MASK_TC67_1x1.nc'\n",
    "ds_tc = xr.open_dataset(fname)\n",
    "dr_mask = ds_tc['transcom_regions']\n",
    "    \n",
    "dr_flux_mask = dr_sink[0,:,:].copy()\n",
    "dr_flux_mask[:,:] = 0.\n",
    "for ilon, lon in enumerate(dr_flux_mask['lon'].values):\n",
    "    for ilat, lat in enumerate(dr_flux_mask['lat'].values):\n",
    "        dr_flux_mask[ilat,ilon] = dr_mask.sel(lat = lat, lon = lon, method=\"nearest\")\n",
    "        \n",
    "#dr_flux_mask.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scaling maps for each month\n",
    "scale_map = dr_sink[0:lag_window,:,:].copy()\n",
    "scale_map[:,:,:] = 0. # scale map, [lag_window, lat, lon]\n",
    "\n",
    "for imonth in range(lag_window):\n",
    "    for ilat in range(len(scale_map.lat)):\n",
    "        for ilon in range(len(scale_map.lon)):\n",
    "            if np.isnan(dr_flux_mask[ilat,ilon].values): scale_map[imonth,ilat,ilon] = scale_lag[imonth,-1] # last one, ocean\n",
    "            else: \n",
    "                mask_nm = int(dr_flux_mask[ilat,ilon].values)\n",
    "                scale_map[imonth,ilat,ilon] = scale_lag[imonth,mask_nm-1] # mask number from 1 to 21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply this scale map to bio flux\n",
    "# plot updates during lag window\n",
    "fig, axes = plt.subplots(3, 2, \n",
    "                         figsize=[14, 14], \n",
    "                         subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "                         gridspec_kw={'hspace': 0.2, 'wspace': 0})\n",
    "\n",
    "# monthly biospheric flux\n",
    "for i in range(lag_window):\n",
    "    \n",
    "    dr_sink[assim_month - lag_window + i,:,:].plot(ax=axes[i,0], \n",
    "                    vmax = 5e9,\n",
    "                    vmin = -5e9,\n",
    "                    cmap = 'RdBu_r',\n",
    "                    add_labels = False,\n",
    "                    cbar_kwargs={'shrink': 0.8})\n",
    "    axes[i,0].set_title(long_name_of_month(assim_month - lag_window + i + 1), loc='left')\n",
    "    axes[i,0].set_title('prior flux', loc='right')\n",
    "    axes[i,0].coastlines()\n",
    "    axes[i,0].gridlines(linestyle = '--')\n",
    "    \n",
    "# adjustments\n",
    "for i in range(lag_window):\n",
    "    adjust_abs = dr_sink[assim_month - lag_window + i,:,:]*(scale_map[i,:,:]-1)\n",
    "    adjust_abs.plot(ax = axes[i,1],\n",
    "                            vmax = 5e9,\n",
    "                            vmin = -5e9,\n",
    "                            cmap = 'RdBu_r',\n",
    "                            add_labels = False,\n",
    "                            cbar_kwargs={'shrink': 0.8})\n",
    "\n",
    "    axes[i,1].set_title(long_name_of_month(assim_month - lag_window + i + 1), loc='left')\n",
    "    axes[i,1].set_title('adjustment', loc='right')\n",
    "    axes[i,1].coastlines()\n",
    "    axes[i,1].gridlines(linestyle = '--')\n",
    "    \n",
    "fig.savefig(curr_dir  + 'flux_scaling.' + short_name_of_month(assim_month) + '.update.png', dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update oceanic flux\n",
    "print('-'*50)\n",
    "print('update oceanic fluxes')\n",
    "\n",
    "ds = xr.open_dataset(f2)\n",
    "data = ds['CO2'].copy()\n",
    "months = np.arange('2000-01', '2001-02', dtype='datetime64[M]')\n",
    "for i in range(lag_window):\n",
    "    imonth = assim_month - lag_window + i\n",
    "    before = data.sel(time = months[imonth])\n",
    "    after = data.sel(time = months[imonth])*scale_map[i,:,:]\n",
    "    # assign this new subset into dataarray\n",
    "    time_dim = before.time\n",
    "    print('updated time slices', time_dim.values)\n",
    "    data.loc[dict(time = time_dim)] = after\n",
    "ds_output = data.to_dataset(name = 'CO2')\n",
    "ds_output.attrs = ds.attrs\n",
    "\n",
    "ds_output.to_netcdf(input_dir + 'Taka2009_CO2_Monthly.updated.' + str(year) + '.' + name_month + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update biospheric flux\n",
    "print('-'*50)\n",
    "print('update biospheric fluxes')\n",
    "\n",
    "ds = xr.open_dataset(f1)\n",
    "data = ds['CO2']\n",
    "\n",
    "scale_map_regrid = data[0:lag_window].copy()\n",
    "scale_map_regrid[:,:,:] = 0.\n",
    "for i in range(lag_window):\n",
    "    for ilon, lon in enumerate(scale_map_regrid['lon'].values):\n",
    "        for ilat, lat in enumerate(scale_map_regrid['lat'].values):\n",
    "            scale_map_regrid[i,ilat,ilon] = scale_map[i,:,:].sel(lat = lat, lon = lon, method=\"nearest\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months = np.arange('2016-01', '2017-02', dtype='datetime64[M]')\n",
    "\n",
    "for i in range(lag_window):\n",
    "    imonth = assim_month - lag_window + i\n",
    "    print('updated months ', months[imonth])\n",
    "    before = data.sel(time = slice(months[imonth], months[imonth+1]))\n",
    "    after  = data.sel(time = slice(months[imonth], months[imonth+1]))*scale_map_regrid[i,:,:]\n",
    "    # assign this new subset into dataarray\n",
    "    time_dim = before.time\n",
    "    #print(time_dim.values)\n",
    "    data.loc[dict(time = time_dim)] = after\n",
    "ds_output = data.to_dataset(name = 'CO2')\n",
    "ds_output.attrs = ds.attrs\n",
    "\n",
    "ds_output.to_netcdf(input_dir + 'NEE.Liang.2016.updated.' + str(year) + '.' + name_month + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated prior error, save it in current and next month directory\n",
    "np.savetxt(next_dir + \"prior_error_\" + short_name_of_month(assim_month+1) + \".txt\", del_X_updated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
