{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection of functions\n",
    "# simple functions could be tested within the cell it is defined\n",
    "# more complex ones uses the cell below to do the testing\n",
    "# rules: \n",
    "# 1, each function should not take longer than 1min to run\n",
    "# 2, not too long... 20 lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"font.size\"] = 12\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gamap_colormap import WhGrYlRd\n",
    "# packages\n",
    "import math\n",
    "import matplotlib.pyplot as plt # load plotting libraries\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import re\n",
    "from bpch2nc import bpch_2_netcdf\n",
    "import scipy.linalg as sp\n",
    "import pandas as pd\n",
    "from util.functions import create_masks\n",
    "# numpy precision\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'May'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same as above, only long names\n",
    "def long_name_of_month(month): # returns long name of month\n",
    "    month_names = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    name_month = month_names[month-1]\n",
    "    return name_month\n",
    "#long_name_of_month(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dec'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input: 3\n",
    "# output: 'Mar'\n",
    "def short_name_of_month(month): # returns short name of month\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    name_month = month_names[month-1]\n",
    "    return name_month\n",
    "#short_name_of_month(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'03'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input: number of month: 1-12\n",
    "# output: a string '01', '02', '03', ..., '10', '11', '12'\n",
    "def month_string(month): # string for a month, input 3 output '03'\n",
    "    if(month >= 10):\n",
    "        mm_str = str(month)\n",
    "    else:\n",
    "        mm_str = '0' + str(month)\n",
    "    return mm_str\n",
    "#month_string(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2018-01-01', '2018-01-02', '2018-01-03', '2018-01-04',\n",
       "       '2018-01-05', '2018-01-06', '2018-01-07', '2018-01-08',\n",
       "       '2018-01-09', '2018-01-10', '2018-01-11', '2018-01-12',\n",
       "       '2018-01-13', '2018-01-14', '2018-01-15', '2018-01-16',\n",
       "       '2018-01-17', '2018-01-18', '2018-01-19', '2018-01-20',\n",
       "       '2018-01-21', '2018-01-22', '2018-01-23', '2018-01-24',\n",
       "       '2018-01-25', '2018-01-26', '2018-01-27', '2018-01-28',\n",
       "       '2018-01-29', '2018-01-30', '2018-01-31'], dtype='datetime64[D]')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input: 2018, 2\n",
    "# output: array(['2018-02-01', '2018-02-02', '2018-02-03', '2018-02-04', ..., '2018-02-27', '2018-02-28'], dtype='datetime64[D]')\n",
    "# needs some work\n",
    "def days_str_in_a_month(year, month): # returns days in a month, in numpy datetime64[D] format\n",
    "    month_str = month_string(month)\n",
    "    if month <= 11:\n",
    "        first_day = str(year) + '-' + month_str + '-01'\n",
    "        month_str_p1 = month_string(month+1)\n",
    "        last_day_p1 = str(year) + '-' + month_str_p1 + '-01'\n",
    "    else:\n",
    "        first_day = str(year) + '-' + month_str + '-01'\n",
    "        month_str_p1 = month_string(1)\n",
    "        last_day_p1 = str(year+1) + '-' + month_str_p1 + '-01'\n",
    "    \n",
    "    return np.arange(first_day, last_day_p1, dtype='datetime64[D]')\n",
    "#days_str_in_a_month(2018,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a correct leap year function! might not needed at all\n",
    "# input: year in integer\n",
    "# output: True if leap year, False if not\n",
    "def leap_year(year):\n",
    "    ans = False\n",
    "    if year%4 == 0 and year%100 !=0:\n",
    "        ans = True\n",
    "    if year%400 == 0:\n",
    "        ans = True\n",
    "    return ans\n",
    "#leap_year(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def days_in_month(year, month):\n",
    "    leap_flag = leap_year(year)\n",
    "    days_in_a_year = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    if leap_flag == True and month == 2: return 29\n",
    "    else: return days_in_a_year[month-1]\n",
    "\n",
    "#days_in_month(2010,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate the area of a spatial grid square from the latitudes and longitudes of the diagonal vertices\n",
    "def area_latlon(lat1, lon1, lat2, lon2):\n",
    "    # This function calculates the area (in km^2) of a spatial grid square, given the latitudes and longitudes of the two diagonal vertices of the grid square.\n",
    "    # lat/lon is in angle; lat: [-90:90]; lon:[-180:180].\n",
    "    # lat1/lon1 and lat2/lon2 are thus the diagonal vertices of the square grid.\n",
    "    lat1 = lat1/180*np.pi\n",
    "    lat2 = lat2/180*np.pi\n",
    "    lon1 = lon1/180*np.pi\n",
    "    lon2 = lon2/180*np.pi\n",
    "    A = np.absolute(6371.009**2*(np.sin(lat2)-np.sin(lat1))*(lon2-lon1))\n",
    "    return A\n",
    "#area_latlon(10,0,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: an xarray dataarray or dataset with lon and lat coords\n",
    "# output: [[lat1,lon1], [lat2,lon2]], smallest box that covers dataset\n",
    "def lat_lon_bounds(ds):\n",
    "    minlat = math.floor(ds.lat.min())\n",
    "    maxlat = math.ceil(ds.lat.max())\n",
    "    minlon = math.floor(ds.lon.min())\n",
    "    maxlon = math.ceil(ds.lon.max())\n",
    "    mins = [minlat, minlon] \n",
    "    maxs = [maxlat, maxlon]\n",
    "    \n",
    "    # round up to nearest number divisible by 5, GEOS-Chem grids keep these grid points even (?)\n",
    "    for i in range(len(mins)):\n",
    "        if mins[i]%5 != 0: mins[i] = mins[i] - mins[i]%5\n",
    "    for i in range(len(maxs)):\n",
    "        if maxs[i]%5 != 0: maxs[i] = maxs[i] + 5 - maxs[i]%5\n",
    "    ans = [mins,maxs]   \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#lat_lon_bounds(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get country total of a variable\n",
    "def country_totals(co2_xarray, countries, varnames):\n",
    "    # create masks using regionmask\n",
    "    mask1 = regionmask.defined_regions.natural_earth.countries_50.mask(co2_xarray)\n",
    "    # sum up total emissions for each country\n",
    "    co2_countries = co2_xarray.groupby(mask1).sum('stacked_lat_lon')\n",
    "    abbrevs = regionmask.defined_regions.natural_earth.countries_50[co2_countries.region.values].abbrevs\n",
    "    names = regionmask.defined_regions.natural_earth.countries_50[co2_countries.region.values].names\n",
    "    co2_countries.coords['abbrevs'] = ('region', abbrevs)\n",
    "    co2_countries.coords['names'] = ('region', names)\n",
    "\n",
    "    country_totals = np.zeros(len(countries))\n",
    "    for i in range(len(countries)):\n",
    "        tmp = co2_countries.isel(region=(co2_countries.names == countries[i]))\n",
    "        country_totals[i] = tmp[varnames[0]].values\n",
    "    return country_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "\n",
    "#countries = ['Germany', 'United Kingdom', 'Italy', 'France', 'Poland', 'Spain']\n",
    "#var    = ['co2_ff']\n",
    "#before = country_totals(ds[var], countries, var)\n",
    "\n",
    "#bar_pos = np.arange(len(countries)) + 1 # position of the bars\n",
    "#fig = plt.figure(figsize=[8, 4])\n",
    "#width = 0.3\n",
    "#bars_before = plt.bar(bar_pos, before*1e-9, width=width, color = 'b', label='before')\n",
    "#plt.xticks(bar_pos, countries)\n",
    "#plt.title('Annual total emission (Tg/yr) of ' + var[0], loc='left')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid an xarray dataarray from finer resolution to coarser resolution (res)\n",
    "# dr is the dataarray\n",
    "def regrid_fine_to_coarse_sum_dr(dr, target, res_lat, res_lon):\n",
    "    target_copy = target.copy()\n",
    "    for ilon, lon in enumerate(target['lon'].values):\n",
    "        for ilat, lat in enumerate(target['lat'].values):\n",
    "            subset = dr.sel(lat=slice(lat-res_lat/2,lat+res_lat/2), lon = slice(lon-res_lon/2,lon+res_lon/2))\n",
    "            target_copy[ilat,ilon] = subset.sum().values\n",
    "    \n",
    "    return target_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid a 3-d (time, lat, lon) xarray dataarray from finer resolution to coarser resolution (res_lat, res_lon)\n",
    "def regrid_fine_to_coarse_sum_dr_monthly(dr, target, res_lat, res_lon):\n",
    "    target_copy = target.copy()\n",
    "    for ilon, lon in enumerate(target['lon'].values):\n",
    "        for ilat, lat in enumerate(target['lat'].values):\n",
    "            subset = dr.sel(lat=slice(lat-res_lat/2,lat+res_lat/2), lon = slice(lon-res_lon/2,lon+res_lon/2))\n",
    "            target_copy[:,ilat,ilon] = subset.sum(dim=('lat','lon')).values\n",
    "            target_copy.attrs = dr.attrs\n",
    "    return target_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid an xarray dataarray from finer resolution to coarser resolution (res)\n",
    "# ds is the dataset, varnames are variables need to be regridded\n",
    "def regrid_fine_to_coarse_sum(ds, varnames, res_lat, res_lon):\n",
    "    # get outer bounds of input data, [[lat1,lon1], [lat2,lon2]] \n",
    "    bounds = lat_lon_bounds(ds)\n",
    "    # target grid\n",
    "    target = xr.DataArray(0, dims=('lat', 'lon'), \n",
    "                            coords={'lat': np.arange(bounds[0][0], bounds[1][0] + res_lat, res_lat), # larger than CHE domain\n",
    "                                    'lon': np.arange(bounds[0][1], bounds[1][1] + res_lon, res_lon)}) # slightly smaller than TNO domain\n",
    "    target = target.astype(dtype='float64')\n",
    "    output = target.to_dataset(name = varnames[0])\n",
    "    for ivar in varnames: output[ivar] = target.copy()\n",
    "    # regridding\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        for ilon, lon in enumerate(target['lon'].values):\n",
    "            for ilat, lat in enumerate(target['lat'].values):\n",
    "                subset = dr.sel(lat=slice(lat-res_lat/2,lat+res_lat/2), lon = slice(lon-res_lon/2,lon+res_lon/2))\n",
    "                target[ilat,ilon] = subset.sum().values\n",
    "                target.attrs = dr.attrs\n",
    "        output[ivar] = target.copy()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#ds_regrid = regrid_fine_to_coarse_sum(ds, ['co2_ff'], 0.25, 0.3125) # to coarse resolution\n",
    "\n",
    "#countries = ['Germany', 'United Kingdom', 'Italy', 'France', 'Poland', 'Spain']\n",
    "#var    = ['co2_ff']\n",
    "#before = country_totals(ds[var], countries, var)\n",
    "#after  = country_totals(ds_regrid[var], countries, var)\n",
    "\n",
    "#bar_pos = np.arange(len(countries)) + 1 # position of the bars\n",
    "#fig = plt.figure(figsize=[9, 4])\n",
    "#width = 0.2\n",
    "#bars_before = plt.bar(bar_pos-0.1, before*1e-9, width=width, color = 'b', label='before')\n",
    "#bars_after  = plt.bar(bar_pos+0.1, after*1e-9, width=width, color = 'g', label='after')\n",
    "#plt.xticks(bar_pos, countries)\n",
    "#plt.title('Annual total emission (Tg/yr) of ' + var[0], loc='left')\n",
    "#plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert kg/year to kg/m2/s\n",
    "# inputs: dataset (xarray), lat and lon, variable names in dataset\n",
    "# outputs: dataset\n",
    "def unit_convert_ds_yearly(ds, varnames, res_lat, res_lon):\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        # calculate grid area (using the area_latlon) and compute flux\n",
    "        for ilat, lat in enumerate(dr['lat'].values):\n",
    "            area = 1e6 * area_latlon(lat1=lat, lat2=lat+res_lat, \n",
    "                                     lon1=10, lon2=10+res_lon) # m^2, longitude doesn't matter\n",
    "            dr[ilat,:] = dr[ilat,:]/(area*3600*24*365) # kg/m2/s\n",
    "        ds[ivar] = dr.copy()\n",
    "        ds[ivar].attrs['units'] = 'kg/m2/s'\n",
    "        ds[ivar].attrs['long_units'] = 'kg(' + ivar + ')/m2/s'\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "##ds['co2_ff'].plot()\n",
    "#ds_flux = unit_convert_ds_yearly(ds, ['co2_ff'], 0.05, 0.1)\n",
    "#ds_flux['co2_ff'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert kg/year to kg/m2/s\n",
    "# inputs: dataarray (xarray), lat and lon, variable names in dataset\n",
    "# outputs: dataarray\n",
    "def unit_convert_dr_yearly(dr, res_lat, res_lon):\n",
    "    dr_copy = dr.copy()\n",
    "    # calculate grid area (using the area_latlon) and compute flux\n",
    "    for ilat, lat in enumerate(dr_copy['lat'].values):\n",
    "        area = 1e6 * area_latlon(lat1=lat, lat2=lat+res_lat, \n",
    "                                    lon1=10, lon2=10+res_lon) # m^2, longitude doesn't matter\n",
    "        dr_copy[ilat,:] = dr_copy[ilat,:]/(area*3600*24*365) # kg/m2/s\n",
    "    dr_copy.attrs['units'] = 'kg/month'\n",
    "    return dr_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#dr = ds['co2_ff']\n",
    "##ds['co2_ff'].plot()\n",
    "#dr_flux = unit_convert_dr_yearly(dr, 0.05, 0.1)\n",
    "#dr_flux.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert annual mean kg/m2/s to kg/year\n",
    "def unit_convert2_ds_yearly(ds, varnames, res_lat, res_lon):\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        # use grid area function\n",
    "        for ilat, lat in enumerate(dr.lat.values):\n",
    "            area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                     lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "            dr[ilat,:] = dr[ilat,:] * area * (3600*24*365) # kg/year\n",
    "        ds[ivar] = dr.copy()\n",
    "        ds[ivar].attrs['units'] = 'kg/year'\n",
    "        ds[ivar].attrs['long_units'] = 'kg(' + ivar + ')/year'\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.25x0.3125.nc' # unit: kg/m2/s\n",
    "#ds = xr.open_dataset(fname)\n",
    "#ds_flux = unit_convert2_ds_yearly(ds, ['co2_ff'], 0.25, 0.3125)\n",
    "#ds_flux['co2_ff'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert annual mean kg/m2/s to kg/year\n",
    "def unit_convert2_dr_yearly(dr, res_lat, res_lon):\n",
    "    dr_copy = dr.copy()\n",
    "        # use grid area function\n",
    "    for ilat, lat in enumerate(dr_copy.lat.values):\n",
    "        area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                    lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "        dr_copy[ilat,:] = dr_copy[ilat,:] * area * (3600*24*365) # kg/year\n",
    "    dr_copy.attrs['units'] = 'kg/year'\n",
    "    return dr_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.25x0.3125.nc' # unit: kg/m2/s\n",
    "#ds = xr.open_dataset(fname)\n",
    "#dr = ds['co2_ff']\n",
    "#dr_flux = unit_convert2_dr_yearly(dr, 0.25, 0.3125)\n",
    "#dr_flux.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert annual mean kg/month to kg/m2/s\n",
    "# works for leap years\n",
    "def unit_convert_dr_monthly(dr, year, res_lat, res_lon):\n",
    "    dr_copy = dr.copy()\n",
    "    days_list = []\n",
    "    for imonth in range(12): days_list.append(days_in_month(year, imonth+1))\n",
    "    # use grid area function\n",
    "    for imonth in range(12):\n",
    "        for ilat, lat in enumerate(dr_copy.lat.values):\n",
    "            area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                     lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "            dr_copy[imonth, ilat, :] = dr_copy[imonth, ilat, :] / (area * days_list[imonth] * (3600*24)) # kg/year\n",
    "    dr_copy.attrs['units'] = 'kg/month'\n",
    "    return dr_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert annual mean kg/m2/s to kg/month\n",
    "# works for leap years\n",
    "def unit_convert2_dr_monthly(dr, year, res_lat, res_lon):\n",
    "    dr_copy = dr.copy()\n",
    "    days_list = []\n",
    "    for imonth in range(12): days_list.append(days_in_month(year, imonth+1))\n",
    "    # use grid area function\n",
    "    for imonth in range(12):\n",
    "        for ilat, lat in enumerate(dr_copy.lat.values):\n",
    "            area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                     lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "            dr_copy[imonth, ilat, :] = dr_copy[imonth, ilat, :] * area * days_list[imonth] * (3600*24) # kg/year\n",
    "    dr_copy.attrs['units'] = 'kg/month'\n",
    "    return dr_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert kg/m2/s to kg/(number of hours)\n",
    "def unit_convert2_hours(dr, res_lat, res_lon, hours):\n",
    "    dr_copy = dr.copy()\n",
    "    # use grid area function\n",
    "    for ilat, lat in enumerate(dr_copy.lat.values):\n",
    "        area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                 lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "        dr_copy[:,ilat,:] = dr_copy[:,ilat,:] * area * (3600*hours) # kg/(#hours)\n",
    "    return dr_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bpch files to netcdf format, \n",
    "# given input directory, a year and month\n",
    "# naming convention is ts_satellite.yyyymmdd.bpch\n",
    "# output format is ts_satellite.yyymmdd.nc\n",
    "# need tracerinfo.dat and diaginfo.dat in the same directory\n",
    "# uses days_str_in_a_month function\n",
    "def bpch_to_nc_mass(data_dir, year, month):\n",
    "    \n",
    "    name_bpch1 = 'ts_satellite.'\n",
    "    \n",
    "    tinfo_file = data_dir + 'tracerinfo.dat'\n",
    "    dinfo_file = data_dir + 'diaginfo.dat'\n",
    "    \n",
    "    days = days_str_in_a_month(year, month)\n",
    "    \n",
    "    for iday in np.arange(len(days)):\n",
    "        day_string = days[iday] # format not right for the following function\n",
    "        #print('converting bpch to netcdf on day: ', day_string)\n",
    "        new_day_string = re.sub(\"[^0-9]\", \"\", str(day_string)) # strip off '-'s\n",
    "\n",
    "        bpchfile = data_dir + name_bpch1 + new_day_string + '.bpch'\n",
    "        ncfile = data_dir + name_bpch1 + new_day_string + '.nc'\n",
    "\n",
    "        bpch_2_netcdf(bpchfile=bpchfile, \n",
    "                      tinfo_file=tinfo_file, \n",
    "                      dinfo_file=dinfo_file, \n",
    "                      ncfile=ncfile)\n",
    "    print('converted daily bpch outputs to netcdf format')\n",
    "    return\n",
    "\n",
    "#bpch_to_nc_mass(data_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018/nd51/',\n",
    "#               year = 2018,\n",
    "#               month = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine a month of daily netcdf files into one file\n",
    "# input file name format has to be str1 + yyyymmdd + str2\n",
    "# output file name will be str1 + yyyymm + str2\n",
    "\n",
    "def combine_daily_to_one(data_dir, year, month, str1, str2):\n",
    "    days = days_str_in_a_month(year, month)\n",
    "    \n",
    "    # get first file, copy attributes, dimensions from it\n",
    "    # prepare output file format\n",
    "    first_day = days[0]\n",
    "    new_day_string = re.sub(\"[^0-9]\", \"\", str(first_day)) # strip off '-'s\n",
    "\n",
    "    first_file = xr.open_dataset(data_dir + str1 + new_day_string + str2)\n",
    "    varnames = list(first_file.data_vars.keys())  # a list of variable names\n",
    "\n",
    "    lon = first_file.lon\n",
    "    lat = first_file.lat\n",
    "    lev = first_file.lev\n",
    "    time = days\n",
    "    target = xr.DataArray(np.nan, coords=[time, lev, lat, lon], dims=['time', 'lev', 'lat', 'lon'])\n",
    "\n",
    "    \n",
    "    output = target.to_dataset(name = 'null')\n",
    "    output.attrs = first_file.attrs\n",
    "    for ivar in varnames: output[ivar] = target.copy()\n",
    "\n",
    "    \n",
    "    # combine the netcdf files into one, monthly\n",
    "    for iday in np.arange(len(days)):\n",
    "        day_string = days[iday]\n",
    "        #print(day_string)\n",
    "        new_day_string = re.sub(\"[^0-9]\", \"\", str(day_string)) # strip off '-'s\n",
    "        \n",
    "        ncfile = data_dir + str1 + new_day_string + str2\n",
    "\n",
    "        ds_tmp = xr.open_dataset(ncfile)\n",
    "    \n",
    "        for ivar in varnames:\n",
    "            output[ivar][iday,:,:,:] = ds_tmp[ivar][0,:,:,:].copy()\n",
    "            output[ivar].attrs = ds_tmp[ivar].attrs\n",
    "    \n",
    "    # output file name\n",
    "    first_day_string = re.sub(\"[^0-9]\", \"\", str(first_day)) # strip off '-'s\n",
    "    monthly_string = first_day_string[0:6]\n",
    "    output.to_netcdf(data_dir + str1 + monthly_string + str2)\n",
    "    print('created ' + str1 + monthly_string + str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 4d arrays to 2d,\n",
    "# input data file name has to be str1 + yyyymm + str2\n",
    "# output file name will be 2d_ + str1 + yyyymm + str2\n",
    "def flatten_4d_to_2d(data_dir, year, month, str1, str2):\n",
    "    input_file = data_dir + str1 + str(year) + month_string(month) + str2\n",
    "    ds = xr.open_dataset(input_file)\n",
    "    varnames = list(ds.data_vars.keys())  # a list of variable names\n",
    "    record = range(len(ds.lon) * len(ds.lat) * len(ds.time)) # length of array\n",
    "    # output data format\n",
    "    target = xr.DataArray(np.nan, coords=[record, ds.lev], dims=['record', 'levels'])\n",
    "    ds_output = target.to_dataset(name = 'null')\n",
    "    \n",
    "    for ivar in varnames: ds_output[ivar] = target.copy()\n",
    "    \n",
    "    flat = ds[ivar][:,0,:,:].to_dataframe() # flatten a variable at one level\n",
    "    flat.reset_index(inplace=True) # get indices to prepare output coordinates\n",
    "    \n",
    "    lat = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lon = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    date = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lat.values = flat['lat']\n",
    "    lon.values = flat['lon']\n",
    "    date.values = flat['time']\n",
    "    ds_output['lat'] = lat\n",
    "    ds_output['lon'] = lon\n",
    "    ds_output['date'] = date\n",
    "    ds_output\n",
    "\n",
    "    for ivar in varnames:\n",
    "        target = xr.DataArray(np.nan, coords=[record, ds.lev], dims=['record', 'levels'])\n",
    "        for ilev in range(len(ds.lev)):\n",
    "            flat = ds[ivar][:,ilev,:,:].to_dataframe() # flatten a variable at one level\n",
    "            target[:,ilev] = flat[ivar] # store output to a dataarray\n",
    "        ds_output[ivar] = target.copy() # store dataarray to dataset\n",
    "        #print(ivar + ' done!')\n",
    "\n",
    "    output_file = '2d_' + str1 + str(year) + month_string(month) + str2\n",
    "    ds_output.to_netcdf(data_dir + output_file)\n",
    "    print('created ' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quite fast for one variable (<1m), but rather slow for 20+ tagged species (>15m)\n",
    "def interpolate_model_to_satellite(mod_dir, sat_dir, year, month, str1_mod, str1_sat):\n",
    "    \n",
    "    # read model and satellite files\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    # read in variables and compute\n",
    "    varnames = list(ds_mod.data_vars.keys())  # list of variable name\n",
    "    needed_vars = [i for i in varnames if i.startswith('SpeciesConc_CO2')] # species var names\n",
    "    record            = ds_mod['record'].values\n",
    "    levels_model      = ds_mod['levels']\n",
    "    surf_press_mod    = ds_mod['PEDGE_S_PSURF']\n",
    "    profile_press_mod = surf_press_mod * levels_model # model pressure at different levels\n",
    "    profile_press_sat = ds_sat['pressure'] # satellite pressure profile of different levels\n",
    "    # find records where measurements are available\n",
    "    surf_press = profile_press_sat[:,19].values\n",
    "    nonzero_record = np.where(surf_press != 0)[0] # loop over these records only\n",
    "    # prepare output dataset\n",
    "    interpolated = ds_sat['pressure'].to_dataset() # output dataset\n",
    "    # variables need not to be interpolated\n",
    "    noneed_interp = ['lat', 'lon', 'date']\n",
    "    for ivar in noneed_interp: interpolated[ivar] = ds_mod[ivar].copy()\n",
    "    # tmp dataarray to store interpolated output\n",
    "    tmp = xr.DataArray(data = np.nan,\n",
    "                       dims=('record', 'levels'),\n",
    "                       coords=[record, ds_mod.levels])\n",
    "    tmp = tmp.astype(dtype = 'float32')\n",
    "    for ivar in needed_vars: interpolated[ivar] = tmp.copy()\n",
    "    \n",
    "    print('interpolation began')\n",
    "    # interpolation\n",
    "    for ivar in needed_vars:\n",
    "        before = ds_mod[ivar] # co2 before interpolation\n",
    "        for irecord in nonzero_record:\n",
    "            var_before  = before[irecord,:].values # a co2 profile\n",
    "            pres_before = np.log(profile_press_mod[irecord].values) # log space\n",
    "            pres_after  = np.log(profile_press_sat[irecord])\n",
    "            # linear interpolation on log space    \n",
    "            interpolated[ivar][irecord,:] = np.interp(x  = pres_after, \n",
    "                                                      xp = np.flip(pres_before), # increasing order\n",
    "                                                      fp = np.flip(var_before))\n",
    "        print(ivar, 'done')\n",
    "    \n",
    "    output_file = mod_dir + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    interpolated.to_netcdf(output_file)\n",
    "    \n",
    "    print('created ' + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc')\n",
    "\n",
    "#interpolate_model_to_satellite(mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018-03/nd51/', \n",
    "#                                   sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "#                                   year = 2018, \n",
    "#                                   month = 3, \n",
    "#                                   str1_mod = '2d_ts_satellite.', \n",
    "#                                   str1_sat = '2d_OCO2_extract_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quite fast for one variable (<1m), but rather slow for 20+ tagged species (>15m)\n",
    "def interpolate_model_to_satellite2(mod_dir, sat_dir, year, month, str1_mod, str1_sat, background):\n",
    "    \n",
    "    # read model and satellite files\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    # read in variables and compute\n",
    "    varnames = list(ds_mod.data_vars.keys())  # list of variable name\n",
    "    needed_vars = [i for i in varnames if i.startswith('SpeciesConc_CO2Tag')] # species var names\n",
    "    record            = ds_mod['record'].values\n",
    "    levels_model      = ds_mod['levels']\n",
    "    surf_press_mod    = ds_mod['PEDGE_S_PSURF']\n",
    "    profile_press_mod = surf_press_mod * levels_model # model pressure at different levels\n",
    "    profile_press_sat = ds_sat['pressure'] # satellite pressure profile of different levels\n",
    "    # find records where measurements are available\n",
    "    surf_press = profile_press_sat[:,19].values\n",
    "    nonzero_record = np.where(surf_press != 0)[0] # loop over these records only\n",
    "    # prepare output dataset\n",
    "    interpolated = ds_sat['pressure'].to_dataset() # output dataset\n",
    "    # variables need not to be interpolated\n",
    "    noneed_interp = ['lat', 'lon', 'date']\n",
    "    for ivar in noneed_interp: interpolated[ivar] = ds_mod[ivar].copy()\n",
    "    # tmp dataarray to store interpolated output\n",
    "    tmp = xr.DataArray(data = np.nan,\n",
    "                       dims=('record', 'levels'),\n",
    "                       coords=[record, ds_mod.levels])\n",
    "    tmp = tmp.astype(dtype = 'float32')\n",
    "    for ivar in needed_vars: interpolated[ivar] = tmp.copy()\n",
    "    \n",
    "    print('interpolation began')\n",
    "    # interpolation\n",
    "    for ivar in needed_vars:\n",
    "        before = ds_mod[ivar] # co2 before interpolation\n",
    "        for irecord in nonzero_record:\n",
    "            var_before  = before[irecord,:].values - background*1e3 # a co2 profile, subtract background (ppm to ppb)\n",
    "            pres_before = np.log(profile_press_mod[irecord].values) # log space\n",
    "            pres_after  = np.log(profile_press_sat[irecord])\n",
    "            # linear interpolation on log space    \n",
    "            interpolated[ivar][irecord,:] = np.interp(x  = pres_after, \n",
    "                                                      xp = np.flip(pres_before), # increasing order\n",
    "                                                      fp = np.flip(var_before))\n",
    "        print(ivar, 'done')\n",
    "    \n",
    "    output_file = mod_dir + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    interpolated.to_netcdf(output_file)\n",
    "    \n",
    "    print('created ' + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def delta_Y(mod_dir, sat_dir, year, month, str1_mod, str1_sat, mode):\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    \n",
    "    # variables needed \n",
    "    varnames = list(ds_mod.data_vars.keys())  # list of variable name\n",
    "    tag_species = [i for i in varnames if i.startswith('SpeciesConc_CO2Tag')] # species var names\n",
    "    \n",
    "    # mask data: predefined region, land vs. ocean, latitudinal bands\n",
    "    mask_directory = '/geos/u73/msadiq/GEOS-Chem/analysis/inversion/data/'\n",
    "    mask_name     = 'flatten_mask.nc'\n",
    "    ds_mask = xr.open_dataset(mask_directory + mask_name)\n",
    "\n",
    "    avg_kern = ds_sat['xco2_averaging_kernel']\n",
    "    co2_pr   = ds_sat['co2_profile_apriori']\n",
    "    pres_wgt = ds_sat['pressure_weight']\n",
    "    op_mode  = ds_sat['operation_mode'] # 0=Nadir, 1=Glint\n",
    "    mode_mask= (op_mode-1)*-1    # mask to mask out glint, 1=Nadir, 0=Glint\n",
    "\n",
    "    # new dataset to store all model xco2\n",
    "    lat = ds_mod['lat']\n",
    "    delta_y_mod = lat.to_dataset()\n",
    "    delta_y_mod['lon'] = ds_mod['lon']\n",
    "    delta_y_mod['date'] = ds_mod['date']\n",
    "    \n",
    "    # loop over tag species to compute delta y0\n",
    "    for ivar in tag_species:   \n",
    "        co2_model = ds_mod[ivar]*1e-3 # unit: ppbv to ppm\n",
    "        #xco2_tmp = pres_wgt * (1 - avg_kern) * co2_pr + pres_wgt * avg_kern * co2_model\n",
    "        xco2_tmp =  pres_wgt * avg_kern * co2_model\n",
    "        xco2 = xco2_tmp.sum(dim = 'levels') # sum along vertical axis, unit: ppm\n",
    "        xco2_land = xco2 * ds_mask['land'][0:len(xco2)]  # exclude ocean\n",
    "        if mode == 'N':\n",
    "            xco2_mode = xco2_land * mode_mask                # select observation mode\n",
    "        else:\n",
    "            xco2_mode = xco2_land \n",
    "\n",
    "        tmp_name = 'X_' + ivar\n",
    "\n",
    "        delta_y_mod[tmp_name] = xco2_mode.copy()\n",
    "        #print(tmp_name + ' done!')\n",
    "    \n",
    "    if mode == 'N':\n",
    "        output_file = mod_dir + 'delta_y0_model_N_' + str(month) + '.nc'\n",
    "    else:\n",
    "        output_file = mod_dir + 'delta_y0_model_' + str(month) + '.nc'\n",
    "    \n",
    "    delta_y_mod.to_netcdf(output_file)\n",
    "    print('created ' + 'delta_y0_model_N_' + str(month) + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imonth = 3\n",
    "#if __name__ == '__main__':\n",
    "#    year = 2018\n",
    "#    for imonth in range(1,13):\n",
    "#        case_name = 'CO2-TC67-2018-' + month_string(imonth)\n",
    "#        mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/' + case_name + '/nd51/'\n",
    "\n",
    "#        delta_Y(mod_dir = mod_dir, sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "#             year = year, month = imonth, \n",
    "#             str1_mod = 'interpolated_2d_ts_satellite.', \n",
    "#             str1_sat = '2d_OCO2_extract_',\n",
    "#             mode = 'N')\n",
    "    #mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018-03/nd51/'\n",
    "    #fname = 'delta_y0_model_N_3.nc'\n",
    "    #fname = '2d_ts_satellite.201803.nc'\n",
    "    #ds = xr.open_dataset(mod_dir + fname)\n",
    "    #ds['SpeciesConc_CO2Tag10'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_rmse(obs_series, model_series):\n",
    "    R = ma.corrcoef(ma.masked_invalid(obs_series), ma.masked_invalid(model_series))\n",
    "    x = obs_series[~np.isnan(obs_series)]\n",
    "    y = model_series[~np.isnan(model_series)]\n",
    "    rmse = np.sqrt(((y - x) ** 2).mean())\n",
    "    format_R = float(\"{0:.2f}\".format(R[0,1]))\n",
    "    format_rmse = float(\"{0:.2f}\".format(rmse))\n",
    "    return format_R, format_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_xco2_diff(diff_before, diff_after, lat_slice, lon_slice, imonth, mod_dir):\n",
    "    '''Produce plots of XCO2 differences\n",
    "    inputs (1d arrays): \n",
    "        diff in XCO2, before and after\n",
    "        lat_slice, lon_slice, lat and lon for each data point\n",
    "        imonth, month number, for plot title\n",
    "    outputs: plots\n",
    "        '''\n",
    "    nobs = len(diff_before)\n",
    "    # Creat target dataarray and dataset\n",
    "    lat_res = 2.    # horizontal resolution of lat and lon you would want\n",
    "    lon_res = 2.5\n",
    "    lat = np.linspace(-90, 90, int(180/lat_res + 1)) # grid\n",
    "    lon = np.linspace(-180, 177.5, int(360/lon_res))\n",
    "    diff_1 = xr.DataArray(data = np.nan, \n",
    "                        dims = ('lat', 'lon'), \n",
    "                        coords = {'lat': lat,\n",
    "                                'lon': lon},\n",
    "                        name = 'diff')\n",
    "    diff_2 = xr.DataArray(data = np.nan, \n",
    "                        dims = ('lat', 'lon'), \n",
    "                        coords = {'lat': lat,\n",
    "                                'lon': lon},\n",
    "                        name = 'diff')\n",
    "    # map 1d data onto dataarray\n",
    "    for i in range(nobs):\n",
    "        lat = int((lat_slice[i].values + 90)/2) # lat index\n",
    "        lon = int((lon_slice[i].values + 180)/2.5)\n",
    "        diff_1[lat, lon] = -diff_before[i]\n",
    "        diff_2[lat, lon] = -diff_after[i]\n",
    "    print('y diff before:',\"{:.2f}\".format(diff_1.mean().values))\n",
    "    print('y diff after:',\"{:.2f}\".format(diff_2.mean().values))\n",
    "\n",
    "    # figure 1, distribution\n",
    "    fig, axes = plt.subplots(1, 2, \n",
    "                             figsize=[14, 6], \n",
    "                             subplot_kw={'projection': ccrs.PlateCarree()},\n",
    "                             gridspec_kw={'hspace': 0.2, 'wspace': 0})\n",
    "    # before\n",
    "    diff_1.plot(ax=axes[0], vmax = 4, add_labels = False, cbar_kwargs={'shrink': 0.5})\n",
    "    axes[0].set_title(short_name_of_month(imonth) + ' XCO2: a prior - OCO2', loc='left')\n",
    "    axes[0].set_title('ppm', loc = 'right')\n",
    "    axes[0].coastlines()\n",
    "    axes[0].gridlines(linestyle = '--')\n",
    "    # after\n",
    "    diff_2.plot(ax=axes[1], vmax = 4, add_labels = False, cbar_kwargs={'shrink': 0.5})\n",
    "    axes[1].set_title(short_name_of_month(imonth) + ' XCO2: a posterior - OCO2', loc='left')\n",
    "    axes[1].set_title('ppm', loc = 'right')\n",
    "    axes[1].coastlines()\n",
    "    axes[1].gridlines(linestyle = '--')\n",
    "\n",
    "    fig.savefig(mod_dir + 'bio_results_map_diff_' + str(imonth) + '.png', dpi=300)\n",
    "    \n",
    "    obs_series = xco2_oco_slice.values\n",
    "    model_series = xco2_mod_slice.values\n",
    "    format_R1, format_rmse1 = r_rmse(obs_series, model_series)\n",
    "    print('R1 is:', format_R1, ' RMSE1 is: ', format_rmse1)\n",
    "    \n",
    "    obs_series = xco2_oco_slice.values\n",
    "    model_series = xco2_oco_slice.values - diff_after\n",
    "    format_R2, format_rmse2 = r_rmse(obs_series, model_series)\n",
    "    print('R2 is:', format_R2, ' RMSE2 is: ', format_rmse2)\n",
    "    \n",
    "    # figure 2, scatter plot\n",
    "    fig = plt.figure(figsize=[5,5])\n",
    "    plt.plot([300,450],[300,450], c='black')\n",
    "    plt.scatter(xco2_oco_slice, xco2_mod_slice, s=0.7, label = 'A prior')\n",
    "    plt.scatter(xco2_oco_slice, xco2_oco_slice - diff_after, s=0.7, label = 'A posterior')\n",
    "    plt.ylim(top   = 420,bottom = 395)\n",
    "    plt.xlim(right = 420,left   = 395)\n",
    "    plt.text(x=405, y=397.5, s='R1: ' + str(format_R1) + ' RMSE1: ' + str(format_rmse1), size = 12)\n",
    "    plt.text(x=405, y=396, s='R2: ' + str(format_R2) + ' RMSE2: ' + str(format_rmse2), size = 12)\n",
    "    plt.title(name_month + ' XCO2 (ppm)')\n",
    "    plt.ylabel('GEOS-Chem')\n",
    "    plt.xlabel('OCO2')\n",
    "    plt.legend(markerscale = 4)\n",
    "    \n",
    "    fig.savefig(mod_dir + 'bio_results_scatter_diff_' + str(imonth) + '.png', dpi=300)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split masks (dataarray) into separate dataarrays, as one dataset, \n",
    "# with 1 for masked area, 0 for elsewhere\n",
    "def split_mask(input_mask):\n",
    "    target = input_mask.copy()\n",
    "    target[:,:] = 0.\n",
    "    ds_masks = target.to_dataset(name = 'MASK1')\n",
    "    nm_masks = int(input_mask.max().values) # number of masks\n",
    "    \n",
    "    for count in range(1,nm_masks+1): # + ocean\n",
    "        target = input_mask.copy()\n",
    "        target[:,:] = 0.\n",
    "        mask_TF = input_mask == count # True or False map\n",
    "        target = mask_TF.where(True)\n",
    "        name_tmp = 'MASK' + str(count)\n",
    "        ds_masks[name_tmp] = target\n",
    "    name_tmp = 'MASK' + str(count+1) # last mask for all nan values, ocean in giorgi mask\n",
    "    ds_masks[name_tmp] = np.isnan(input_mask).where(True)\n",
    "    return ds_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def compare_XCO2(mod_dir, sat_dir, year, month, str1_mod, str1_sat, mode):\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    \n",
    "    # mask data: predefined region, land vs. ocean, latitudinal bands\n",
    "    mask_directory = '/geos/u73/msadiq/GEOS-Chem/analysis/inversion/data/'\n",
    "    mask_name     = 'flatten_mask.nc'\n",
    "    ds_mask = xr.open_dataset(mask_directory + mask_name)\n",
    "\n",
    "    avg_kern = ds_sat['xco2_averaging_kernel']\n",
    "    co2_pr   = ds_sat['co2_profile_apriori']\n",
    "    pres_wgt = ds_sat['pressure_weight']\n",
    "    op_mode  = ds_sat['operation_mode'] # 0=Nadir, 1=Glint\n",
    "    mode_mask= (op_mode-1)*-1    # mask to mask out glint, 1=Nadir, 0=Glint\n",
    "\n",
    "    # model simulated CO2 concentration\n",
    "    co2_model = ds_mod['SpeciesConc_CO2']*1e-3 # unit: ppbv to ppmv \n",
    "    co2_profile = pres_wgt * (1 - avg_kern) * co2_pr + pres_wgt * avg_kern * co2_model\n",
    "    # sum up to get column CO2\n",
    "    xco2_model = co2_profile.sum(dim = 'levels')      # sum along vertical axis, unit: ppbv to ppm\n",
    "\n",
    "    xco2_model_mode = xco2_model * mode_mask # extract desired mode of observation: Nadir\n",
    "    xco2_oco2_mode = ds_sat['xco2'] * mode_mask\n",
    "\n",
    "    obs_series = xco2_oco2_mode.values\n",
    "    model_series = xco2_model_mode.values\n",
    "    obs_series[obs_series==0] = 'nan'\n",
    "    model_series[model_series==0] = 'nan'\n",
    "    \n",
    "    format_R, format_rmse = r_rmse(obs_series, model_series)\n",
    "    print('R is:', format_R, ' RMSE is: ', format_rmse)\n",
    "\n",
    "    xco2_model_land = xco2_model_mode * ds_mask['land'][0:len(xco2_model)]\n",
    "    xco2_model_land[xco2_model_land==0] = 'nan'\n",
    "    xco2_oco2_land = xco2_oco2_mode * ds_mask['land'][0:len(xco2_model)]\n",
    "    xco2_oco2_land[xco2_oco2_land==0] = 'nan'\n",
    "\n",
    "    fig = plt.figure(figsize=[5,5])\n",
    "    name_month = short_name_of_month(month)\n",
    "    for region in ['high_lat', 'mid_lat', 'low_lat']:\n",
    "        xco2_model_mask = xco2_model_land * ds_mask[region][0:len(xco2_model_land)]\n",
    "        xco2_model_mask[xco2_model_mask==0] = 'nan'\n",
    "        xco2_oco2_mask = xco2_oco2_land * ds_mask[region][0:len(xco2_model_land)]\n",
    "        xco2_oco2_mask[xco2_oco2_mask==0] = 'nan'\n",
    "\n",
    "        plt.scatter(xco2_oco2_mask, xco2_model_mask, s=0.7, label = region)\n",
    "        plt.plot([300,450],[300,450], c='r')\n",
    "        plt.ylim(top   = 420,bottom = 395)\n",
    "        plt.xlim(right = 420,left   = 395)\n",
    "        plt.title(name_month + ' XCO2 (ppm)')\n",
    "        plt.ylabel('GEOS-Chem')\n",
    "        plt.xlabel('OCO2')\n",
    "        plt.legend(markerscale = 4)\n",
    "\n",
    "        plt.text(x=410, y=399, s='R: ' + str(format_R), size = 12)\n",
    "        plt.text(x=410, y=398, s='RMSE: ' + str(format_rmse), size = 12)\n",
    "        fig.savefig(mod_dir + '/mod_vs_obs_XCO2_latitudinal_'+ mode + '_' + name_month + '.png', dpi=300)\n",
    "\n",
    "\n",
    "    diff = xco2_oco2_land - xco2_model_land   # diff to calculate a posteriori\n",
    "    new_data = diff.to_dataset(name = 'diff')\n",
    "    new_data['xco2_oco2'] = xco2_oco2_land\n",
    "    new_data['xco2_model'] = xco2_model_land\n",
    "    new_data['xco2_error'] = ds_sat['xco2_uncertainty']\n",
    "    new_data['lat'] = ds_mod['lat']\n",
    "    new_data['lon'] = ds_mod['lon']\n",
    "    new_data['date'] = ds_mod['date']\n",
    "    new_data.to_netcdf(mod_dir + 'XCO2_mod_and_oco2_' + mode + '_' + name_month + '.nc')\n",
    "\n",
    "    # Creat target dataarray and dataset\n",
    "    lat_res = 2    # horizontal resolution of lat and lon you would want\n",
    "    lon_res = 2.5\n",
    "    lat = np.linspace(-90, 90, int(180/lat_res + 1)) # grid\n",
    "    lon = np.linspace(-180, 177.5, int(360/lon_res))\n",
    "    days = len(diff)/(len(lat)*len(lon))\n",
    "\n",
    "    var_3d = xr.DataArray(data = np.nan, \n",
    "                          dims = ('days', 'lat', 'lon'), \n",
    "                          coords = {'days': range(int(days)),\n",
    "                                    'lat': lat,\n",
    "                                    'lon': lon},\n",
    "                          name = 'diff')\n",
    "    var_3d = var_3d.astype(dtype='float32')\n",
    "\n",
    "    diff2 = xco2_model_land - xco2_oco2_land # diff to map onto global map\n",
    "    var_3d.values = diff2.values.reshape((int(days),len(lat),len(lon)))\n",
    "    \n",
    "    var_2d = var_3d.mean(dim='days')\n",
    "    # plot after mapping\n",
    "    fig = plt.figure(figsize=[8, 8])\n",
    "    proj=ccrs.PlateCarree()\n",
    "    ax = plt.subplot(111, projection=proj)\n",
    "    # \n",
    "    var_2d.plot(ax=ax, vmax = 3, add_labels = False, cbar_kwargs={'shrink': 0.4})\n",
    "    ax.set_title(name_month + ' XCO2: a posterior - OCO2', loc = 'left');\n",
    "    ax.set_title('ppm', loc = 'right')\n",
    "    ax.coastlines()\n",
    "    ax.gridlines(linestyle = '--')\n",
    "    \n",
    "\n",
    "    fig.savefig(mod_dir + 'diff_map_' + name_month + '.png', dpi=300)\n",
    "\n",
    "    ds_output = var_3d.to_dataset()\n",
    "    var_3d.values = xco2_model_land.values.reshape((int(days),len(lat),len(lon)))\n",
    "    ds_output['mod'] = var_3d.copy()\n",
    "    var_3d.values = xco2_oco2_land.values.reshape((int(days),len(lat),len(lon)))\n",
    "    ds_output['obs'] = var_3d.copy()\n",
    "    ds_output.to_netcdf(mod_dir + 'XCO2_diff_' + str(month) + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_oco2_monthly(year, month, input_file):\n",
    "    \n",
    "    # names of variables need to extract \n",
    "    var_names  = ['xco2', \n",
    "                  'psurf', \n",
    "                  'xco2_averaging_kernel',\n",
    "                  'co2_profile_apriori',\n",
    "                  'pressure_weight',\n",
    "                  'xco2_uncertainty',\n",
    "                  'operation_mode']\n",
    "\n",
    "    # first and last day of extraction\n",
    "    first_day = str(year) + '-' + month_string(month) + '-01'\n",
    "    output_file ='/geos/u73/msadiq/satellite/oco-2/OCO2_extract_' + str(year) + month_string(month) + '.nc'\n",
    "\n",
    "    if(month == 12):\n",
    "        last_day_p1 = str(year+1) + '-01-01' # last day plus 1\n",
    "    else:\n",
    "        last_day_p1 = str(year) + '-' + month_string(month+1) + '-01' # last day plus 1\n",
    "\n",
    "    ds = xr.open_dataset(input_file, engine='netcdf4')\n",
    "    sigma_levels = ds['sigma_levels'] #['xco2_averaging_kernel'].name\n",
    "\n",
    "    # convert time input to match the format of sound_id\n",
    "    first_day_digital = re.sub(\"[^0-9]\", \"\", first_day)\n",
    "    last_day_p1_digital = re.sub(\"[^0-9]\", \"\", last_day_p1)\n",
    "    begin = int(first_day_digital + '000000')  # begin and end of time slice we want to look at\n",
    "    end = int(last_day_p1_digital + '000000')  # OCO-2 format\n",
    "    print('begining sound id of extraction: ' + str(begin))\n",
    "    print('end: ' + str(end))\n",
    "\n",
    "    # get a slice of data within begin and end time\n",
    "    ds_slice = ds.sel(sounding_id=slice(begin,end)) # xarray Dataset\n",
    "\n",
    "    lon_series = ds_slice['longitude']              # lon and lat position, 1d\n",
    "    lat_series = ds_slice['latitude']\n",
    "    sound_id   = ds_slice['sounding_id']            # sound id, 1d\n",
    "    sigma      = ds['sigma_levels']                 # sigma levels, 20 values\n",
    "    # xarray dataarray\n",
    "\n",
    "    # position dataframe, used in for loops to locate\n",
    "    df_position = pd.DataFrame({'sound_id': sound_id, \n",
    "                                'lon': lon_series, \n",
    "                                'lat': lat_series})\n",
    "\n",
    "    # Creat target dataarray and dataset\n",
    "    lat_res = 2    # horizontal resolution of lat and lon you would want\n",
    "    lon_res = 2.5\n",
    "    lat = np.linspace(-90, 90, int(180/lat_res + 1)) # grid\n",
    "    lon = np.linspace(-180, 177.5, int(360/lon_res))\n",
    "    levels = ds_slice.sigma_levels.values\n",
    "\n",
    "    day_1   = np.array(first_day,dtype='datetime64[D]')\n",
    "    day_end = np.array(last_day_p1,dtype='datetime64[D]')\n",
    "    days    = np.arange(day_1, day_end, dtype='datetime64[D]') # time dimension of output\n",
    "\n",
    "    var_3d = xr.DataArray(data = 0, \n",
    "                          dims = ('date', 'lat', 'lon'), \n",
    "                          coords = {'date': days,\n",
    "                                    'lat': lat,\n",
    "                                    'lon': lon},\n",
    "                          name = '')\n",
    "    var_3d = var_3d.astype(dtype='float32')\n",
    "\n",
    "    var_4d = xr.DataArray(data = 0, \n",
    "                          dims = ('date', 'lev', 'lat', 'lon'), # same as model order\n",
    "                          coords = {'date': days,\n",
    "                                    'lev': levels,\n",
    "                                    'lat': lat,\n",
    "                                    'lon': lon},\n",
    "                          name = 'xco2_averaging_kernel')\n",
    "\n",
    "    var_4d = var_4d.astype(dtype='float32')\n",
    "    oco2 = var_4d.to_dataset() # initialise a dataset to store all dataarrays\n",
    "\n",
    "    for ivar in var_names:\n",
    "        nm_dim = len(ds[ivar].dims)\n",
    "        if(nm_dim == 1):\n",
    "            oco2[ivar] = var_3d.copy(deep=True)\n",
    "        else:\n",
    "            oco2[ivar] = var_4d.copy(deep=True)\n",
    "\n",
    "\n",
    "    # map 1d or 2d arrays to target grid and store in dataset\n",
    "    for iday in np.arange(len(days)-1):\n",
    "        day1=re.sub(\"[^0-9]\", \"\", str(days[iday]))\n",
    "        day2=re.sub(\"[^0-9]\", \"\", str(days[iday+1]))\n",
    "        begin = int(str(day1) + '000000')  # begin and end of time slice we want to look at\n",
    "        end = int(str(day2) + '000000')  # OCO-2 format\n",
    "\n",
    "        # get a slice of position data within a day\n",
    "        df_time_slice = df_position[df_position['sound_id'].between(begin, end)]\n",
    "\n",
    "        for ilat in np.arange(len(lat)-1):\n",
    "            # get a slice of position data within a degree of latitude band\n",
    "            df_slice_lat = df_time_slice[df_time_slice['lat'].between(lat[ilat]-0.5*lat_res,lat[ilat]+0.5*lat_res, inclusive = True)]\n",
    "\n",
    "            for ilon in np.arange(len(lon)-1):\n",
    "                # get a slice of position data within a degree of longitude band, i.e. a grid cell in one day\n",
    "                df_slice_lon = df_slice_lat[df_slice_lat['lon'].between(lon[ilon]-0.5*lon_res,lon[ilon]+0.5*lon_res, inclusive = True)]\n",
    "\n",
    "                if len(df_slice_lon) != 0: # check if zero\n",
    "                    sound_slice = df_slice_lon.sound_id.values # localtion of points, in sound id                \n",
    "                    ds_slice = ds.sel(sounding_id=sound_slice)\n",
    "\n",
    "                    for ivar in var_names:\n",
    "                        var_slice = ds_slice[ivar]\n",
    "                        if(len(var_slice.dims) == 1):\n",
    "                            oco2[ivar][iday,ilat,ilon] = var_slice.mean().values\n",
    "                        else:\n",
    "                            oco2[ivar][iday,:,ilat,ilon] = var_slice.mean(dim='sounding_id').values\n",
    "\n",
    "        print(days[iday])\n",
    "        \n",
    "    oco2.to_netcdf(output_file)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_oco2_monthly(year, month):\n",
    "    \n",
    "    name_nc_in = 'OCO2_extract_' + str(year) + month_string(month) + '.nc'\n",
    "\n",
    "    # Name of input Netcdf file\n",
    "    input_directory = '/geos/u73/msadiq/satellite/oco-2/'\n",
    "    output_directory = input_directory\n",
    "\n",
    "    input_file = input_directory + name_nc_in # full name\n",
    "    # Name of output netCDF file\n",
    "    output_file = output_directory + '2d_' + name_nc_in\n",
    "    \n",
    "    ds = xr.open_dataset(input_file)\n",
    "    sigma_levels = ds.coords['lev']\n",
    "    \n",
    "    varnames = list(ds.data_vars.keys())  # Get a list of variable names. The expression is a bit cumbersome. Just copy and paste it for now.\n",
    "    nvar = len(varnames)  # how many elements in the list?\n",
    "\n",
    "    nm_lev = len(ds.coords['lev'])\n",
    "    nm_lon = len(ds.coords['lon'])\n",
    "    nm_lat = len(ds.coords['lat'])\n",
    "    nm_days = len(ds.coords['date'])\n",
    "\n",
    "    record = range(nm_lon * nm_lat * nm_days)\n",
    " \n",
    "    # 2d data array to store flattened data\n",
    "    foo_2d = xr.DataArray(data = 0,\n",
    "                          dims=('record', 'levels'),\n",
    "                          coords=[record, ds.coords['lev']])\n",
    "    foo_2d = foo_2d.astype(dtype = 'float32')\n",
    "    # 1d data array to store flattened data\n",
    "    foo_1d = xr.DataArray(data = 0,\n",
    "                          dims=('record'),\n",
    "                          coords={record})\n",
    "    foo_1d = foo_1d.astype(dtype = 'float32')\n",
    "\n",
    "    # dataset to store following dataarrays\n",
    "    ds_output = foo_2d.to_dataset(name = 'xco2')\n",
    "    ds_output = ds_output.astype(dtype = 'float32')\n",
    "\n",
    "    flat = ds['xco2_averaging_kernel'][:,0,:,:].to_dataframe()\n",
    "    # flatten a variable at one level\n",
    "    flat.reset_index(inplace=True) \n",
    "\n",
    "    lat = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lon = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    date = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lat.values = flat['lat']\n",
    "    lon.values = flat['lon']\n",
    "    date.values = flat['date']\n",
    "    ds_output['lat'] = lat\n",
    "    ds_output['lon'] = lon\n",
    "    ds_output['date'] = date\n",
    "\n",
    "    for ivar in varnames:\n",
    "        if len(ds[ivar].dims) == 4:\n",
    "            for ilev in range(nm_lev):\n",
    "                flat = ds[ivar][:,ilev,:,:].to_dataframe() # flatten a variable at one level\n",
    "                foo_2d[:,ilev] = flat[ivar].values # store output to a dataarray\n",
    "            ds_output[ivar] = foo_2d.copy() # store dataarray to dataset\n",
    "\n",
    "        else:\n",
    "            flat = ds[ivar].to_dataframe()\n",
    "            foo_1d.values = flat[ivar].values\n",
    "            ds_output[ivar] = foo_1d.copy() # store dataarray to dataset\n",
    "        print(ivar + ' done!')\n",
    "    \n",
    "    # pressure profile\n",
    "    pressure = ds_output.psurf * ds_output.coords['levels']\n",
    "    ds_output['pressure'] = pressure\n",
    "    \n",
    "    ds_output.attrs['comment'] = 'flattened from 4d NetCDF file, after extraction from OCO2'\n",
    "    \n",
    "    ds_output.to_netcdf(path=output_file)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
