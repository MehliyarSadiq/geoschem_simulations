{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection of functions\n",
    "# simple functions could be tested within the cell it is defined\n",
    "# more complex ones uses the cell below to do the testing\n",
    "# rules: \n",
    "# 1, each function should not take longer than 1min to run\n",
    "# 2, not too long... 20 lines?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plots\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"font.size\"] = 12\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gamap_colormap import WhGrYlRd\n",
    "# packages\n",
    "import math\n",
    "import matplotlib.pyplot as plt # load plotting libraries\n",
    "import cartopy.crs as ccrs\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import regionmask\n",
    "import re\n",
    "from bpch2nc import bpch_2_netcdf\n",
    "import scipy.linalg as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, only long names\n",
    "def long_name_of_month(month): # returns long name of month\n",
    "    month_names = ['January', 'February', 'March', 'April', 'May', 'June', \n",
    "                   'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    name_month = month_names[month-1]\n",
    "    return name_month\n",
    "#long_name_of_month(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: 3\n",
    "# output: 'Mar'\n",
    "def short_name_of_month(month): # returns short name of month\n",
    "    month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    name_month = month_names[month-1]\n",
    "    return name_month\n",
    "#short_name_of_month(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: 2018, 2\n",
    "# output: array(['2018-02-01', '2018-02-02', '2018-02-03', '2018-02-04', ..., '2018-02-27', '2018-02-28'], dtype='datetime64[D]')\n",
    "# needs some work\n",
    "def days_str_in_a_month(year, month): # returns days in a month, in numpy datetime64[D] format\n",
    "    month_str = month_string(month)\n",
    "    if month <= 11:\n",
    "        first_day = str(year) + '-' + month_str + '-01'\n",
    "        month_str_p1 = month_string(month+1)\n",
    "        last_day_p1 = str(year) + '-' + month_str_p1 + '-01'\n",
    "    else:\n",
    "        first_day = str(year) + '-' + month_str + '-01'\n",
    "        month_str_p1 = month_string(1)\n",
    "        last_day_p1 = str(year+1) + '-' + month_str_p1 + '-01'\n",
    "    \n",
    "    return np.arange(first_day, last_day_p1, dtype='datetime64[D]')\n",
    "#days_str_in_a_month(2018,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: number of month: 1-12\n",
    "# output: a string '01', '02', '03', ..., '10', '11', '12'\n",
    "def month_string(month): # string for a month, input 3 output '03'\n",
    "    if(month >= 10):\n",
    "        mm_str = str(month)\n",
    "    else:\n",
    "        mm_str = '0' + str(month)\n",
    "    return mm_str\n",
    "#month_string(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a correct leap year function! might not needed at all\n",
    "# input: year in integer\n",
    "# output: True if leap year, False if not\n",
    "def leap_year(year):\n",
    "    ans = False\n",
    "    if year%4 == 0 and year%100 !=0:\n",
    "        ans = True\n",
    "    if year%400 == 0:\n",
    "        ans = True\n",
    "    return ans\n",
    "leap_year(2012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_in_month(year, month):\n",
    "    leap_flag = leap_year(year)\n",
    "    days_in_a_year = [31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    if leap_flag == True and month == 2: return 29\n",
    "    else: return days_in_a_year[month-1]\n",
    "\n",
    "#days_in_month(2010,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approximate the area of a spatial grid square from the latitudes and longitudes of the diagonal vertices\n",
    "def area_latlon(lat1, lon1, lat2, lon2):\n",
    "    # This function calculates the area (in km^2) of a spatial grid square, given the latitudes and longitudes of the two diagonal vertices of the grid square.\n",
    "    # lat/lon is in angle; lat: [-90:90]; lon:[-180:180].\n",
    "    # lat1/lon1 and lat2/lon2 are thus the diagonal vertices of the square grid.\n",
    "    lat1 = lat1/180*np.pi\n",
    "    lat2 = lat2/180*np.pi\n",
    "    lon1 = lon1/180*np.pi\n",
    "    lon2 = lon2/180*np.pi\n",
    "    A = np.absolute(6371.009**2*(np.sin(lat2)-np.sin(lat1))*(lon2-lon1))\n",
    "    return A\n",
    "#area_latlon(10,0,11,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: an xarray dataarray or dataset with lon and lat coords\n",
    "# output: [[lat1,lon1], [lat2,lon2]], smallest box that covers dataset\n",
    "def lat_lon_bounds(ds):\n",
    "    minlat = math.floor(ds.lat.min())\n",
    "    maxlat = math.ceil(ds.lat.max())\n",
    "    minlon = math.floor(ds.lon.min())\n",
    "    maxlon = math.ceil(ds.lon.max())\n",
    "    mins = [minlat, minlon] \n",
    "    maxs = [maxlat, maxlon]\n",
    "    \n",
    "    # round up to nearest number divisible by 5, GEOS-Chem grids keep these grid points even (?)\n",
    "    for i in range(len(mins)):\n",
    "        if mins[i]%5 != 0: mins[i] = mins[i] - mins[i]%5\n",
    "    for i in range(len(maxs)):\n",
    "        if maxs[i]%5 != 0: maxs[i] = maxs[i] + 5 - maxs[i]%5\n",
    "    ans = [mins,maxs]   \n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#lat_lon_bounds(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get country total of a variable\n",
    "def country_totals(co2_xarray, countries, varnames):\n",
    "    # create masks using regionmask\n",
    "    mask1 = regionmask.defined_regions.natural_earth.countries_50.mask(co2_xarray)\n",
    "    # sum up total emissions for each country\n",
    "    co2_countries = co2_xarray.groupby(mask1).sum('stacked_lat_lon')\n",
    "    abbrevs = regionmask.defined_regions.natural_earth.countries_50[co2_countries.region.values].abbrevs\n",
    "    names = regionmask.defined_regions.natural_earth.countries_50[co2_countries.region.values].names\n",
    "    co2_countries.coords['abbrevs'] = ('region', abbrevs)\n",
    "    co2_countries.coords['names'] = ('region', names)\n",
    "\n",
    "    country_totals = np.zeros(len(countries))\n",
    "    for i in range(len(countries)):\n",
    "        tmp = co2_countries.isel(region=(co2_countries.names == countries[i]))\n",
    "        country_totals[i] = tmp[varnames[0]].values\n",
    "    return country_totals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "\n",
    "#countries = ['Germany', 'United Kingdom', 'Italy', 'France', 'Poland', 'Spain']\n",
    "#var    = ['co2_ff']\n",
    "#before = country_totals(ds[var], countries, var)\n",
    "\n",
    "#bar_pos = np.arange(len(countries)) + 1 # position of the bars\n",
    "#fig = plt.figure(figsize=[8, 4])\n",
    "#width = 0.3\n",
    "#bars_before = plt.bar(bar_pos, before*1e-9, width=width, color = 'b', label='before')\n",
    "#plt.xticks(bar_pos, countries)\n",
    "#plt.title('Annual total emission (Tg/yr) of ' + var[0], loc='left')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regrid an xarray dataarray from finer resolution to coarser resolution (res)\n",
    "# ds is the dataset, varnames are variables need to be regridded\n",
    "def regrid_fine_to_coarse_sum(ds, varnames, res_lat, res_lon):\n",
    "    # get outer bounds of input data, [[lat1,lon1], [lat2,lon2]] \n",
    "    bounds = lat_lon_bounds(ds)\n",
    "    # target grid\n",
    "    target = xr.DataArray(0, dims=('lat', 'lon'), \n",
    "                            coords={'lat': np.arange(bounds[0][0], bounds[1][0] + res_lat, res_lat), # larger than CHE domain\n",
    "                                    'lon': np.arange(bounds[0][1], bounds[1][1] + res_lon, res_lon)}) # slightly smaller than TNO domain\n",
    "    target = target.astype(dtype='float64')\n",
    "    output = target.to_dataset(name = varnames[0])\n",
    "    for ivar in varnames: output[ivar] = target.copy()\n",
    "    # regridding\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        for ilon, lon in enumerate(target['lon'].values):\n",
    "            for ilat, lat in enumerate(target['lat'].values):\n",
    "                subset = dr.sel(lat=slice(lat-res_lat/2,lat+res_lat/2), lon = slice(lon-res_lon/2,lon+res_lon/2))\n",
    "                target[ilat,ilon] = subset.sum().values\n",
    "                target.attrs = dr.attrs\n",
    "        output[ivar] = target.copy()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#ds_regrid = regrid_fine_to_coarse_sum(ds, ['co2_ff'], 0.25, 0.3125)\n",
    "\n",
    "#countries = ['Germany', 'United Kingdom', 'Italy', 'France', 'Poland', 'Spain']\n",
    "#var    = ['co2_ff']\n",
    "#before = country_totals(ds[var], countries, var)\n",
    "#after  = country_totals(ds_regrid[var], countries, var)\n",
    "\n",
    "#bar_pos = np.arange(len(countries)) + 1 # position of the bars\n",
    "#fig = plt.figure(figsize=[9, 4])\n",
    "#width = 0.2\n",
    "#bars_before = plt.bar(bar_pos-0.1, before*1e-9, width=width, color = 'b', label='before')\n",
    "#bars_after  = plt.bar(bar_pos+0.1, after*1e-9, width=width, color = 'g', label='after')\n",
    "#plt.xticks(bar_pos, countries)\n",
    "#plt.title('Annual total emission (Tg/yr) of ' + var[0], loc='left')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert kg/year to kg/m2/s\n",
    "def unit_convert1(ds, varnames, res_lat, res_lon):\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        # calculate grid area (using the area_latlon) and compute flux\n",
    "        for ilat, lat in enumerate(dr['lat'].values):\n",
    "            area = 1e6 * area_latlon(lat1=lat, lat2=lat+res_lat, \n",
    "                                     lon1=10, lon2=10+res_lon) # m^2, longitude doesn't matter\n",
    "            dr[ilat,:] = dr[ilat,:]/(area*3600*24*365) # kg/m2/s\n",
    "        ds[ivar] = dr.copy()\n",
    "        ds[ivar].attrs['units'] = 'kg/m2/s'\n",
    "        ds[ivar].attrs['long_units'] = 'kg(' + ivar + ')/m2/s'\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.05x0.1.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#ds_flux = unit_convert1(ds, ['co2_ff'], 0.05, 0.1)\n",
    "#ds_flux['co2_ff'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert annual mean kg/m2/s to kg/year\n",
    "def unit_convert2(ds, varnames, res_lat, res_lon):\n",
    "    for ivar in varnames:\n",
    "        dr = ds[ivar]\n",
    "        # use grid area function\n",
    "        for ilat, lat in enumerate(dr.lat.values):\n",
    "            area = 1e6 * area_latlon(lat1 = lat, lat2 = lat + res_lat,\n",
    "                                     lon1 = 10, lon2 = 10 + res_lon) # m^2, longitude doesn't matter\n",
    "            dr[ilat,:] = dr[ilat,:] * area * (3600*24*365) # kg/year\n",
    "        ds[ivar] = dr.copy()\n",
    "        ds[ivar].attrs['units'] = 'kg/year'\n",
    "        ds[ivar].attrs['long_units'] = 'kg(' + ivar + ')/year'\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fname = '/geos/d21/msadiq/TNO-GHGco/gridded/TNO_2018_0.25x0.3125.nc'\n",
    "#ds = xr.open_dataset(fname)\n",
    "#ds_flux = unit_convert2(ds, ['co2_ff'], 0.25, 0.3125)\n",
    "#ds_flux['co2_ff'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert bpch files to netcdf format, \n",
    "# given input directory, a year and month\n",
    "# naming convention is ts_satellite.yyyymmdd.bpch\n",
    "# output format is ts_satellite.yyymmdd.nc\n",
    "# need tracerinfo.dat and diaginfo.dat in the same directory\n",
    "# uses days_str_in_a_month function\n",
    "def bpch_to_nc_mass(data_dir, year, month):\n",
    "    \n",
    "    name_bpch1 = 'ts_satellite.'\n",
    "    \n",
    "    tinfo_file = data_dir + 'tracerinfo.dat'\n",
    "    dinfo_file = data_dir + 'diaginfo.dat'\n",
    "    \n",
    "    days = days_str_in_a_month(year, month)\n",
    "    \n",
    "    for iday in np.arange(len(days)):\n",
    "        day_string = days[iday] # format not right for the following function\n",
    "        #print('converting bpch to netcdf on day: ', day_string)\n",
    "        new_day_string = re.sub(\"[^0-9]\", \"\", str(day_string)) # strip off '-'s\n",
    "\n",
    "        bpchfile = data_dir + name_bpch1 + new_day_string + '.bpch'\n",
    "        ncfile = data_dir + name_bpch1 + new_day_string + '.nc'\n",
    "\n",
    "        bpch_2_netcdf(bpchfile=bpchfile, \n",
    "                      tinfo_file=tinfo_file, \n",
    "                      dinfo_file=dinfo_file, \n",
    "                      ncfile=ncfile)\n",
    "    print('converted daily bpch outputs to netcdf format')\n",
    "    return\n",
    "\n",
    "#bpch_to_nc_mass(data_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018/nd51/',\n",
    "#               year = 2018,\n",
    "#               month = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine a month of daily netcdf files into one file\n",
    "# input file name format has to be str1 + yyyymmdd + str2\n",
    "# output file name will be str1 + yyyymm + str2\n",
    "\n",
    "def combine_daily_to_one(data_dir, year, month, str1, str2):\n",
    "    days = days_str_in_a_month(year, month)\n",
    "    \n",
    "    # get first file, copy attributes, dimensions from it\n",
    "    # prepare output file format\n",
    "    first_day = days[0]\n",
    "    new_day_string = re.sub(\"[^0-9]\", \"\", str(first_day)) # strip off '-'s\n",
    "\n",
    "    first_file = xr.open_dataset(data_dir + str1 + new_day_string + str2)\n",
    "    varnames = list(first_file.data_vars.keys())  # a list of variable names\n",
    "\n",
    "    lon = first_file.lon\n",
    "    lat = first_file.lat\n",
    "    lev = first_file.lev\n",
    "    time = days\n",
    "    target = xr.DataArray(np.nan, coords=[time, lev, lat, lon], dims=['time', 'lev', 'lat', 'lon'])\n",
    "\n",
    "    \n",
    "    output = target.to_dataset(name = 'null')\n",
    "    output.attrs = first_file.attrs\n",
    "    for ivar in varnames: output[ivar] = target.copy()\n",
    "\n",
    "    \n",
    "    # combine the netcdf files into one, monthly\n",
    "    for iday in np.arange(len(days)):\n",
    "        day_string = days[iday]\n",
    "        #print(day_string)\n",
    "        new_day_string = re.sub(\"[^0-9]\", \"\", str(day_string)) # strip off '-'s\n",
    "        \n",
    "        ncfile = data_dir + str1 + new_day_string + str2\n",
    "\n",
    "        ds_tmp = xr.open_dataset(ncfile)\n",
    "    \n",
    "        for ivar in varnames:\n",
    "            output[ivar][iday,:,:,:] = ds_tmp[ivar][0,:,:,:].copy()\n",
    "            output[ivar].attrs = ds_tmp[ivar].attrs\n",
    "    \n",
    "    # output file name\n",
    "    first_day_string = re.sub(\"[^0-9]\", \"\", str(first_day)) # strip off '-'s\n",
    "    monthly_string = first_day_string[0:6]\n",
    "    output.to_netcdf(data_dir + str1 + monthly_string + str2)\n",
    "    print('created ' + str1 + monthly_string + str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten 4d arrays to 2d,\n",
    "# input data file name has to be str1 + yyyymm + str2\n",
    "# output file name will be 2d_ + str1 + yyyymm + str2\n",
    "def flatten_4d_to_2d(data_dir, year, month, str1, str2):\n",
    "    input_file = data_dir + str1 + str(year) + month_string(month) + str2\n",
    "    ds = xr.open_dataset(input_file)\n",
    "    varnames = list(ds.data_vars.keys())  # a list of variable names\n",
    "    record = range(len(ds.lon) * len(ds.lat) * len(ds.time)) # length of array\n",
    "    # output data format\n",
    "    target = xr.DataArray(np.nan, coords=[record, ds.lev], dims=['record', 'levels'])\n",
    "    ds_output = target.to_dataset(name = 'null')\n",
    "    \n",
    "    for ivar in varnames: ds_output[ivar] = target.copy()\n",
    "    \n",
    "    flat = ds[ivar][:,0,:,:].to_dataframe() # flatten a variable at one level\n",
    "    flat.reset_index(inplace=True) # get indices to prepare output coordinates\n",
    "    \n",
    "    lat = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lon = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    date = xr.DataArray(0, coords=[record], dims=['record'])\n",
    "    lat.values = flat['lat']\n",
    "    lon.values = flat['lon']\n",
    "    date.values = flat['time']\n",
    "    ds_output['lat'] = lat\n",
    "    ds_output['lon'] = lon\n",
    "    ds_output['date'] = date\n",
    "    ds_output\n",
    "\n",
    "    for ivar in varnames:\n",
    "        target = xr.DataArray(np.nan, coords=[record, ds.lev], dims=['record', 'levels'])\n",
    "        for ilev in range(len(ds.lev)):\n",
    "            flat = ds[ivar][:,ilev,:,:].to_dataframe() # flatten a variable at one level\n",
    "            target[:,ilev] = flat[ivar] # store output to a dataarray\n",
    "        ds_output[ivar] = target.copy() # store dataarray to dataset\n",
    "        #print(ivar + ' done!')\n",
    "\n",
    "    output_file = '2d_' + str1 + str(year) + month_string(month) + str2\n",
    "    ds_output.to_netcdf(data_dir + output_file)\n",
    "    print('created ' + output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quite fast for one variable (<1m), but rather slow for 20+ tagged species (>15m)\n",
    "def interpolate_model_to_satellite(mod_dir, sat_dir, year, month, str1_mod, str1_sat):\n",
    "    \n",
    "    # read model and satellite files\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    # read in variables and compute\n",
    "    varnames = list(ds_mod.data_vars.keys())  # list of variable name\n",
    "    needed_vars = [i for i in varnames if i.startswith('SpeciesConc_CO2Tag')] # species var names\n",
    "    record            = ds_mod['record'].values\n",
    "    levels_model      = ds_mod['levels']\n",
    "    surf_press_mod    = ds_mod['PEDGE_S_PSURF']\n",
    "    profile_press_mod = surf_press_mod * levels_model # model pressure at different levels\n",
    "    profile_press_sat = ds_sat['pressure'] # satellite pressure profile of different levels\n",
    "    # find records where measurements are available\n",
    "    surf_press = profile_press_sat[:,19].values\n",
    "    nonzero_record = np.where(surf_press != 0)[0] # loop over these records only\n",
    "    # prepare output dataset\n",
    "    interpolated = ds_sat['pressure'].to_dataset() # output dataset\n",
    "    # variables need not to be interpolated\n",
    "    noneed_interp = ['lat', 'lon', 'date']\n",
    "    for ivar in noneed_interp: interpolated[ivar] = ds_mod[ivar].copy()\n",
    "    # tmp dataarray to store interpolated output\n",
    "    tmp = xr.DataArray(data = np.nan,\n",
    "                       dims=('record', 'levels'),\n",
    "                       coords=[record, ds_mod.levels])\n",
    "    tmp = tmp.astype(dtype = 'float32')\n",
    "    for ivar in needed_vars: interpolated[ivar] = tmp.copy()\n",
    "    \n",
    "    print('interpolation began')\n",
    "    # interpolation\n",
    "    for ivar in needed_vars:\n",
    "        before = ds_mod[ivar] # co2 before interpolation\n",
    "        for irecord in nonzero_record:\n",
    "            var_before  = before[irecord,:].values # a co2 profile\n",
    "            pres_before = np.log(profile_press_mod[irecord].values) # log space\n",
    "            pres_after  = np.log(profile_press_sat[irecord])\n",
    "            # linear interpolation on log space    \n",
    "            interpolated[ivar][irecord,:] = np.interp(x  = pres_after, \n",
    "                                                      xp = np.flip(pres_before), # increasing order\n",
    "                                                      fp = np.flip(var_before))\n",
    "        print(ivar, 'done')\n",
    "    \n",
    "    output_file = mod_dir + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    interpolated.to_netcdf(output_file)\n",
    "    \n",
    "    print('created ' + 'interpolated_' + str1_mod + str(year) + month_string(month) + '.nc')\n",
    "\n",
    "#interpolate_model_to_satellite(mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018-03/nd51/', \n",
    "#                                   sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "#                                   year = 2018, \n",
    "#                                   month = 3, \n",
    "#                                   str1_mod = '2d_ts_satellite.', \n",
    "#                                   str1_sat = '2d_OCO2_extract_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "def delta_Y(mod_dir, sat_dir, year, month, str1_mod, str1_sat, mode):\n",
    "    mod_file = str1_mod + str(year) + month_string(month) + '.nc'\n",
    "    sat_file = str1_sat + str(year) + month_string(month) + '.nc'\n",
    "    ds_mod = xr.open_dataset(mod_dir + mod_file)\n",
    "    ds_sat = xr.open_dataset(sat_dir + sat_file)\n",
    "    \n",
    "    # variables needed \n",
    "    varnames = list(ds_mod.data_vars.keys())  # list of variable name\n",
    "    tag_species = [i for i in varnames if i.startswith('SpeciesConc_CO2Tag')] # species var names\n",
    "    \n",
    "    # mask data: predefined region, land vs. ocean, latitudinal bands\n",
    "    mask_directory = '/geos/u73/msadiq/GEOS-Chem/analysis/inversion/data/'\n",
    "    mask_name     = 'flatten_mask.nc'\n",
    "    ds_mask = xr.open_dataset(mask_directory + mask_name)\n",
    "\n",
    "    avg_kern = ds_sat['xco2_averaging_kernel']\n",
    "    co2_pr   = ds_sat['co2_profile_apriori']\n",
    "    pres_wgt = ds_sat['pressure_weight']\n",
    "    op_mode  = ds_sat['operation_mode'] # 0=Nadir, 1=Glint\n",
    "    mode_mask= (op_mode-1)*-1    # mask to mask out glint, 1=Nadir, 0=Glint\n",
    "\n",
    "    # new dataset to store all model xco2\n",
    "    lat = ds_mod['lat']\n",
    "    delta_y_mod = lat.to_dataset()\n",
    "    delta_y_mod['lon'] = ds_mod['lon']\n",
    "    delta_y_mod['date'] = ds_mod['date']\n",
    "    \n",
    "    # loop over tag species to compute delta y0\n",
    "    for ivar in tag_species:   \n",
    "        co2_model = ds_mod[ivar]*1e-3 # unit: ppbv to ppm\n",
    "        #xco2_tmp = pres_wgt * (1 - avg_kern) * co2_pr + pres_wgt * avg_kern * co2_model\n",
    "        xco2_tmp =  pres_wgt * avg_kern * co2_model\n",
    "        xco2 = xco2_tmp.sum(dim = 'levels') # sum along vertical axis, unit: ppm\n",
    "        xco2_land = xco2 * ds_mask['land'][0:len(xco2)]  # exclude ocean\n",
    "        if mode == 'N':\n",
    "            xco2_mode = xco2_land * mode_mask                # select observation mode\n",
    "        else:\n",
    "            xco2_mode = xco2_land \n",
    "\n",
    "        tmp_name = 'X_' + ivar\n",
    "\n",
    "        delta_y_mod[tmp_name] = xco2_mode.copy()\n",
    "        #print(tmp_name + ' done!')\n",
    "\n",
    "    # check if 2 vars are different\n",
    "    #diff = delta_y_mod['X_SpeciesConc_CO2Tag11'] - delta_y_mod['X_SpeciesConc_CO2Tag2']\n",
    "    #diff.plot()\n",
    "    \n",
    "    if mode == 'N':\n",
    "        output_file = mod_dir + 'delta_y0_model_N_' + str(month) + '.nc'\n",
    "    else:\n",
    "        output_file = mod_dir + 'delta_y0_model_' + str(month) + '.nc'\n",
    "    \n",
    "    delta_y_mod.to_netcdf(output_file)\n",
    "    print('created ' + 'delta_y0_model_N_' + str(month) + '.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imonth = 3\n",
    "#if __name__ == '__main__':\n",
    "#    year = 2018\n",
    "#    for imonth in range(1,13):\n",
    "#        case_name = 'CO2-2018-' + month_string(imonth)\n",
    "#        mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/' + case_name + '/nd51/'\n",
    "\n",
    "#        delta_Y(mod_dir = mod_dir, sat_dir = '/geos/u73/msadiq/satellite/oco-2/', \n",
    "#             year = year, month = imonth, \n",
    "#             str1_mod = 'interpolated_2d_ts_satellite.', \n",
    "#             str1_sat = '2d_OCO2_extract_',\n",
    "#             mode = 'N')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_dir = '/geos/u73/msadiq/GEOS-Chem/rundirs/ensemble_runs/CO2-2018-03/nd51/'\n",
    "#fname = 'delta_y0_model_N_3.nc'\n",
    "#fname = '2d_ts_satellite.201803.nc'\n",
    "#ds = xr.open_dataset(mod_dir + fname)\n",
    "#ds['SpeciesConc_CO2Tag10'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
